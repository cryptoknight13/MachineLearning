{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d485656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "print(torch.__version__)\n",
    "\n",
    "import time\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "        \n",
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, n_hiddens_per_conv_layer, n_hiddens_per_fc_layer, n_outputs, \n",
    "                 patch_size_per_conv_layer, stride_per_conv_layer, activation_function='tanh', device='cpu'):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        n_conv_layers = len(n_hiddens_per_conv_layer)\n",
    "        if (len(patch_size_per_conv_layer) != n_conv_layers or\n",
    "            len(stride_per_conv_layer) != n_conv_layers):\n",
    "            raise Exception('The lengths of n_hiddens_per_conv_layer, patch_size_per_conv_layer, and stride_per_conv_layer must be equal.')\n",
    "        \n",
    "        self.activation_function = torch.tanh if activation_function == 'tanh' else torch.relu\n",
    "        \n",
    "        # Create all convolutional layers\n",
    "        # First argument to first Conv2d is number of channels for each pixel.\n",
    "        # Just 1 for our grayscale images.\n",
    "        n_in = input_shape[0]\n",
    "        input_hw = input_shape[1]  # = input_shape[2]\n",
    "        self.conv_layers = torch.nn.ModuleList()\n",
    "        for nh, patch_size, stride in zip(n_hiddens_per_conv_layer,\n",
    "                                          patch_size_per_conv_layer,\n",
    "                                          stride_per_conv_layer):\n",
    "            self.conv_layers.append( torch.nn.Conv2d(n_in, nh, kernel_size=patch_size, stride=stride) )\n",
    "            conv_layer_output_hw = (input_hw - patch_size) // stride + 1\n",
    "            input_hw = conv_layer_output_hw  # for next trip through this loop\n",
    "            n_in = nh\n",
    "\n",
    "        # Create all fully connected layers.  First must determine number of inputs to first\n",
    "        # fully-connected layer that results from flattening the images coming out of the last\n",
    "        # convolutional layer.\n",
    "        n_in = input_hw ** 2 * n_in  # n_hiddens_per_fc_layer[0]\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for nh in n_hiddens_per_fc_layer:\n",
    "            self.fc_layers.append( torch.nn.Linear(n_in, nh) )\n",
    "            n_in = nh\n",
    "\n",
    "        output_layer = torch.nn.Linear(n_in, n_outputs)\n",
    "        self.fc_layers.append(output_layer)\n",
    "        \n",
    "        output_layer.weight.data[:] = 0.0\n",
    "        output_layer.bias.data[:] = 0.0\n",
    "\n",
    "        self.loss_trace = []\n",
    "        self.accuracy_trace = []\n",
    "        \n",
    "        self.to(self.device)\n",
    "\n",
    "\n",
    "    def _forward_all_outputs(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        Ys = [X]\n",
    "        for conv_layer in self.conv_layers:\n",
    "            Ys.append( self.activation_function(conv_layer(Ys[-1])) )\n",
    "\n",
    "        for layeri, fc_layer in enumerate(self.fc_layers[:-1]):\n",
    "            if layeri == 0:\n",
    "                flattend_inputs = Ys[-1].reshape(n_samples, -1)\n",
    "                Ys.append( self.activation_function(fc_layer(flattend_inputs)) )\n",
    "            else:\n",
    "                Ys.append( self.activation_function(fc_layer(Ys[-1])) )\n",
    "\n",
    "        if len(self.fc_layers) == 1:  # no fully connected hidden layers\n",
    "            flattend_inputs = Ys[-1].reshape(n_samples, -1)\n",
    "            Ys.append(self.fc_layers[-1](flattend_inputs))\n",
    "        else:\n",
    "            Ys.append(self.fc_layers[-1](Ys[-1]))\n",
    "        return Ys\n",
    "\n",
    "\n",
    "    def _forward(self, X):\n",
    "        Ys = self._forward_all_outputs(X)\n",
    "        return Ys[-1]\n",
    "    \n",
    "\n",
    "    def to_torch(self, M, torch_type=torch.FloatTensor):\n",
    "        if not isinstance(M, torch.Tensor):\n",
    "            return torch.from_numpy(M).type(torch_type).to(self.device)\n",
    "        return M\n",
    "        \n",
    "    def percent_correct(self, Y_classes, T):\n",
    "        if isinstance(T, torch.Tensor):\n",
    "            T = T.cpu().numpy()\n",
    "        return (Y_classes == T).mean() * 100\n",
    "    \n",
    "    def train(self, Xtrain, Ttrain, batch_size, n_epochs, learning_rate, method='sgd', verbose=True,\n",
    "              Xval=None, Tval=None):\n",
    "        \n",
    "        # Assuming Ttrain includes all possible class labels\n",
    "        self.classes = np.unique(Ttrain)\n",
    "\n",
    "        # Set data matrices to torch.tensors if not already.\n",
    "\n",
    "        Xtrain = self.to_torch(Xtrain)\n",
    "        Ttrain = self.to_torch(Ttrain, torch.LongTensor)\n",
    "        Xval = self.to_torch(Xval) if Xval is not None else None\n",
    "        Tval = self.to_torch(Tval, torch.LongTensor) if Tval is not None else None\n",
    "        \n",
    "        Xtrain.requires_grad_(True)\n",
    "\n",
    "        if method == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        loss_f = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            if batch_size == -1:\n",
    "                num_batches = 1\n",
    "            else:\n",
    "                num_batches = Xtrain.shape[0] // batch_size\n",
    "\n",
    "            loss_sum = 0\n",
    "            class_train_sum = 0\n",
    "            \n",
    "            for k in range(num_batches):\n",
    "                \n",
    "                start = k * batch_size\n",
    "                end = (k + 1) * batch_size\n",
    "                X_batch = Xtrain[start:end, ...]\n",
    "                T_batch = Ttrain[start:end, ...]\n",
    "                \n",
    "                Y = self._forward(X_batch)\n",
    "                \n",
    "                loss = loss_f(Y, T_batch)\n",
    "                loss.backward()\n",
    "\n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss_sum += loss\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    class_train_sum += self.percent_correct(self.use(X_batch)[0], T_batch)\n",
    "                    \n",
    "            self.loss_trace.append((loss_sum.item() / num_batches))\n",
    "            percent_correct_train = class_train_sum / num_batches\n",
    "            if Xval is not None:\n",
    "                with torch.no_grad():\n",
    "                    percent_correct_val = self.percent_correct(self.use(Xval)[0], Tval)\n",
    "                self.accuracy_trace.append([percent_correct_train, percent_correct_val])\n",
    "            else:\n",
    "                self.accuracy_trace.append(percent_correct_train)\n",
    "                \n",
    "            if verbose and (epoch + 1) % (n_epochs // 10) == 0:\n",
    "                print(method, 'Epoch', epoch + 1, 'Loss', self.loss_trace[-1])\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _softmax(self, Y):\n",
    "        '''Apply to final layer weighted sum outputs'''\n",
    "        # Trick to avoid overflow\n",
    "        maxY = torch.max(Y, axis=1)[0].reshape((-1,1))\n",
    "        expY = torch.exp(Y - maxY)\n",
    "        denom = torch.sum(expY, axis=1).reshape((-1, 1))\n",
    "        Y = expY / denom\n",
    "        return Y\n",
    "\n",
    "\n",
    "    def use(self, X):\n",
    "        # Set input matrix to torch.tensors if not already.\n",
    "        with torch.no_grad():\n",
    "            X = self.to_torch(X)\n",
    "            Y = self._forward(X)\n",
    "            probs = self._softmax(Y).cpu().numpy()\n",
    "            classes = self.classes[np.argmax(probs, axis=1)]\n",
    "            return classes, probs\n",
    "\n",
    "    def get_loss_trace(self):\n",
    "        return self.loss_trace\n",
    "\n",
    "    def get_accuracy_trace(self):\n",
    "        return self.accuracy_trace\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
